{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/cedro3/Transformer/blob/master/transformer_en_run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NZgA2TMZcYIe"
   },
   "source": [
    "# Transformerによる英語データのネガポジ判定と判定根拠の可視化\n",
    "\n",
    "・使用するデータセットはIMDbです。これは、映画のレビュー(英文)からセンテンスを取り出し、それがポジテイブな表現なのか、ネガティブな表現なのかをまとめたものです。\\\n",
    "・学習後、テスト文章で推論を行い、その文章のどの単語が判断根拠になっているか(Attention)を可視化します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Githubのコピー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ai9T70ScccNJ"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/cedro3/Transformer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3-Jg-sd1ccWK"
   },
   "outputs": [],
   "source": [
    "cd Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 日本語fastTextモデルのダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x8TIKrBOqcy_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import tarfile\n",
    "\n",
    "os.makedirs('data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q-43PdlKruwS"
   },
   "outputs": [],
   "source": [
    "# fastTextの公式の英語学習済みモデル（650MB）をダウンロード。時間が5分ほどかかります\n",
    "url = \"https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\"\n",
    "save_path = \"./data/wiki-news-300d-1M.vec.zip\"\n",
    "if not os.path.exists(save_path):\n",
    "    urllib.request.urlretrieve(url, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hoTHyvcPrzqp"
   },
   "outputs": [],
   "source": [
    "# フォルダ「data」内の「/wiki-news-300d-1M.vec.zip」を解凍する\n",
    "\n",
    "zipf = zipfile.ZipFile(\"./data/wiki-news-300d-1M.vec.zip\")  # zip > zipf\n",
    "zipf.extractall(\"./data/\")  # ZIPを解凍  # zip > zipf\n",
    "zipf.close()  # ZIPファイルをクローズ    # zip > zipf\n",
    "\n",
    "# フォルダ「data」内にフォルダ「wiki-news-300d-1M.vec」というものができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iJASbjTHcYIh"
   },
   "source": [
    "# コード本体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L0zl-vatcYIh"
   },
   "outputs": [],
   "source": [
    "# パッケージのimport\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9IBWgTe3cYIl"
   },
   "outputs": [],
   "source": [
    "# 乱数のシードを設定\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5c7udEkecYIp"
   },
   "source": [
    "# DatasetとDataLoaderを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4DGwhqocYIp"
   },
   "outputs": [],
   "source": [
    "from dataloader_en import get_IMDb_DataLoaders_and_TEXT\n",
    "\n",
    "# 読み込み\n",
    "train_dl, val_dl, test_dl, TEXT = get_IMDb_DataLoaders_and_TEXT(\n",
    "    max_length=256, batch_size=64)\n",
    "\n",
    "# 辞書オブジェクトにまとめる\n",
    "dataloaders_dict = {\"train\": train_dl, \"val\": val_dl}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nq6Y-BKxcYIu"
   },
   "source": [
    "# ネットワークモデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lx33RtQ6cYIu"
   },
   "outputs": [],
   "source": [
    "from transformer import TransformerClassification  ####\n",
    "\n",
    "# モデル構築\n",
    "net = TransformerClassification(\n",
    "    text_embedding_vectors=TEXT.vocab.vectors, d_model=300, max_seq_len=256, output_dim=2)\n",
    "\n",
    "# ネットワークの初期化を定義\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        # Liner層の初期化\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "\n",
    "# 訓練モードに設定\n",
    "net.train()\n",
    "\n",
    "# TransformerBlockモジュールを初期化実行\n",
    "net.net3_1.apply(weights_init)\n",
    "net.net3_2.apply(weights_init)\n",
    "\n",
    "\n",
    "print('ネットワーク設定完了')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IwgC2x82cYIy"
   },
   "source": [
    "# 損失関数と最適化手法を定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k8-cxceDcYIz"
   },
   "outputs": [],
   "source": [
    "# 損失関数の設定\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# nn.LogSoftmax()を計算してからnn.NLLLoss(negative log likelihood loss)を計算\n",
    "\n",
    "# 最適化手法の設定\n",
    "learning_rate = 2e-5\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1piTApx0cYI2"
   },
   "source": [
    "# 学習・検証を実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hlgcvCVAcYI3"
   },
   "outputs": [],
   "source": [
    "# モデルを学習させる関数を作成\n",
    "\n",
    "\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "\n",
    "    # GPUが使えるかを確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス：\", device)\n",
    "    print('-----start-------')\n",
    "    # ネットワークをGPUへ\n",
    "    net.to(device)\n",
    "\n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "        # epochごとの訓練と検証のループ\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()  # モデルを訓練モードに\n",
    "            else:\n",
    "                net.eval()   # モデルを検証モードに\n",
    "\n",
    "            epoch_loss = 0.0  # epochの損失和\n",
    "            epoch_corrects = 0  # epochの正解数\n",
    "\n",
    "            # データローダーからミニバッチを取り出すループ\n",
    "            for batch in (dataloaders_dict[phase]):\n",
    "                # batchはTextとLableの辞書オブジェクト\n",
    "\n",
    "                # GPUが使えるならGPUにデータを送る\n",
    "                inputs = batch.Text[0].to(device)  # 文章\n",
    "                labels = batch.Label.to(device)  # ラベル\n",
    "\n",
    "                # optimizerを初期化\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                    # mask作成\n",
    "                    input_pad = 1  # 単語のIDにおいて、'<pad>': 1 なので\n",
    "                    input_mask = (inputs != input_pad)\n",
    "\n",
    "                    # Transformerに入力\n",
    "                    outputs, _, _ = net(inputs, input_mask)\n",
    "                    loss = criterion(outputs, labels)  # 損失を計算\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
    "\n",
    "                    # 訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    # 結果の計算\n",
    "                    epoch_loss += loss.item() * inputs.size(0)  # lossの合計を更新\n",
    "                    # 正解数の合計を更新\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            # epochごとのlossと正解率\n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double(\n",
    "            ) / len(dataloaders_dict[phase].dataset)\n",
    "\n",
    "            print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
    "                                                                           phase, epoch_loss, epoch_acc))\n",
    "\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lPpWWoGVcYI6"
   },
   "outputs": [],
   "source": [
    "# 学習・検証を実行する\n",
    "num_epochs = 10\n",
    "net_trained = train_model(net, dataloaders_dict,\n",
    "                          criterion, optimizer, num_epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U34M69axcYI_"
   },
   "source": [
    "# テストデータでの正解率を求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Efdn0D-ucYI_"
   },
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net_trained.eval()   # モデルを検証モードに\n",
    "net_trained.to(device)\n",
    "\n",
    "epoch_corrects = 0  # epochの正解数\n",
    "\n",
    "for batch in (test_dl):  # testデータのDataLoader\n",
    "    # batchはTextとLableの辞書オブジェクト\n",
    "    \n",
    "    # GPUが使えるならGPUにデータを送る\n",
    "    inputs = batch.Text[0].to(device)  # 文章\n",
    "    labels = batch.Label.to(device)  # ラベル\n",
    "\n",
    "    # 順伝搬（forward）計算\n",
    "    with torch.set_grad_enabled(False):\n",
    "\n",
    "        # mask作成\n",
    "        input_pad = 1  # 単語のIDにおいて、'<pad>': 1 なので\n",
    "        input_mask = (inputs != input_pad)\n",
    "\n",
    "        # Transformerに入力\n",
    "        outputs, _, _ = net_trained(inputs, input_mask)\n",
    "        _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
    "\n",
    "        # 結果の計算\n",
    "        # 正解数の合計を更新\n",
    "        epoch_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "# 正解率\n",
    "epoch_acc = epoch_corrects.double() / len(test_dl.dataset)\n",
    "\n",
    "print('テストデータ{}個での正解率：{:.4f}'.format(len(test_dl.dataset),epoch_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ePM7sOM9cYJC"
   },
   "source": [
    "# Attentionの可視化で判定根拠を探る\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PHg0Hw-wcYJC"
   },
   "outputs": [],
   "source": [
    "# HTMLを作成する関数を実装\n",
    "\n",
    "\n",
    "def highlight(word, attn):\n",
    "    \"Attentionの値が大きいと文字の背景が濃い赤になるhtmlを出力させる関数\"\n",
    "\n",
    "    html_color = '#%02X%02X%02X' % (\n",
    "        255, int(255*(1 - attn)), int(255*(1 - attn)))\n",
    "    return '<span style=\"background-color: {}\"> {}</span>'.format(html_color, word)\n",
    "\n",
    "\n",
    "def mk_html(index, batch, preds, normlized_weights_1, normlized_weights_2, TEXT):\n",
    "    \"HTMLデータを作成する\"\n",
    "\n",
    "    # indexの結果を抽出\n",
    "    sentence = batch.Text[0][index]  # 文章\n",
    "    label = batch.Label[index]  # ラベル\n",
    "    pred = preds[index]  # 予測\n",
    "\n",
    "    # indexのAttentionを抽出と規格化\n",
    "    attens1 = normlized_weights_1[index, 0, :]  # 0番目の<cls>のAttention\n",
    "    attens1 /= attens1.max()\n",
    "\n",
    "    attens2 = normlized_weights_2[index, 0, :]  # 0番目の<cls>のAttention\n",
    "    attens2 /= attens2.max()\n",
    "\n",
    "    # ラベルと予測結果を文字に置き換え\n",
    "    if label == 0:\n",
    "        label_str = \"Negative\"\n",
    "    else:\n",
    "        label_str = \"Positive\"\n",
    "\n",
    "    if pred == 0:\n",
    "        pred_str = \"Negative\"\n",
    "    else:\n",
    "        pred_str = \"Positive\"\n",
    "\n",
    "    # 表示用のHTMLを作成する\n",
    "    html = '正解ラベル：{}<br>推論ラベル：{}<br><br>'.format(label_str, pred_str)\n",
    "\n",
    "    # 1段目のAttention\n",
    "    html += '[TransformerBlockの1段目のAttentionを可視化]<br>'\n",
    "    for word, attn in zip(sentence, attens1):\n",
    "        html += highlight(TEXT.vocab.itos[word], attn)\n",
    "    html += \"<br><br>\"\n",
    "\n",
    "    # 2段目のAttention\n",
    "    html += '[TransformerBlockの2段目のAttentionを可視化]<br>'\n",
    "    for word, attn in zip(sentence, attens2):\n",
    "        html += highlight(TEXT.vocab.itos[word], attn)\n",
    "\n",
    "    html += \"<br><br>\"\n",
    "\n",
    "    return html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YU9T3vJycYJG"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# Transformerで処理\n",
    "\n",
    "# ミニバッチの用意\n",
    "batch = next(iter(test_dl))\n",
    "\n",
    "# GPUが使えるならGPUにデータを送る\n",
    "inputs = batch.Text[0].to(device)  # 文章\n",
    "labels = batch.Label.to(device)  # ラベル\n",
    "\n",
    "# mask作成\n",
    "input_pad = 1  # 単語のIDにおいて、'<pad>': 1 なので\n",
    "input_mask = (inputs != input_pad)\n",
    "\n",
    "# Transformerに入力\n",
    "outputs, normlized_weights_1, normlized_weights_2 = net_trained(\n",
    "    inputs, input_mask)\n",
    "_, preds = torch.max(outputs, 1)  # ラベルを予測\n",
    "\n",
    "\n",
    "index = 3  # 出力させたいデータ\n",
    "html_output = mk_html(index, batch, preds, normlized_weights_1,\n",
    "                      normlized_weights_2, TEXT)  # HTML作成\n",
    "HTML(html_output)  # HTML形式で出力\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nqW9l3CBcYJJ"
   },
   "outputs": [],
   "source": [
    "index = 61  # 出力させたいデータ\n",
    "html_output = mk_html(index, batch, preds, normlized_weights_1,\n",
    "                      normlized_weights_2, TEXT)  # HTML作成\n",
    "HTML(html_output)  # HTML形式で出力\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "53-l2Y03cYJM"
   },
   "source": [
    "以上"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "transformer_en_run.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
